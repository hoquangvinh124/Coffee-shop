# â˜• Promotional Response Prediction - Coffee Shop ML Project

## ğŸ¯ Má»¥c tiÃªu dá»± Ã¡n

XÃ¢y dá»±ng mÃ´ hÃ¬nh Machine Learning Ä‘á»ƒ **dá»± bÃ¡o pháº£n á»©ng khÃ¡ch hÃ ng vá»›i khuyáº¿n mÃ£i**, giÃºp quÃ¡n cafe tá»‘i Æ°u hÃ³a chiáº¿n dá»‹ch marketing vÃ  tÄƒng doanh thu thÃ´ng qua targeting thÃ´ng minh.

---

## ğŸ“Š Tá»•ng quan Dataset

- **Sá»‘ lÆ°á»£ng records**: 64,000 giao dá»‹ch khÃ¡ch hÃ ng
- **Features**: 9 features gá»‘c â†’ 36 features sau feature engineering
- **Target**: `conversion` (binary: 0 = khÃ´ng mua, 1 = mua)
- **Class imbalance**: 85.32% khÃ´ng chuyá»ƒn Ä‘á»•i, 14.68% chuyá»ƒn Ä‘á»•i (5.81:1)

### Features gá»‘c:

1. **recency** - Sá»‘ ngÃ y tá»« láº§n mua cuá»‘i (1-12 ngÃ y)
2. **history** - Tá»•ng chi tiÃªu lá»‹ch sá»­ ($29.99 - $3,345.93)
3. **used_discount** - ÄÃ£ dÃ¹ng discount trÆ°á»›c Ä‘Ã¢y (0/1)
4. **used_bogo** - ÄÃ£ dÃ¹ng BOGO trÆ°á»›c Ä‘Ã¢y (0/1)
5. **zip_code** - Khu vá»±c (Urban/Surburban/Rural)
6. **is_referral** - KhÃ¡ch hÃ ng tá»« referral (0/1)
7. **channel** - KÃªnh tiáº¿p cáº­n (Phone/Web/Multichannel)
8. **offer** - Loáº¡i khuyáº¿n mÃ£i (Discount/BOGO/No Offer)
9. **conversion** - Káº¿t quáº£ mua hÃ ng (target)

---

## ğŸš€ Pipeline Triá»ƒn Khai

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)

**File**: `notebooks/01_eda_analysis.py`

**PhÃ¡t hiá»‡n chÃ­nh**:

- âœ… KhÃ´ng cÃ³ missing values
- âš ï¸ Class imbalance nghiÃªm trá»ng (5.81:1) â†’ cáº§n SMOTE
- ğŸ“ˆ **Recency** áº£nh hÆ°á»Ÿng lá»›n: KhÃ¡ch mua gáº§n Ä‘Ã¢y (1-3 ngÃ y) cÃ³ tá»· lá»‡ conversion cao nháº¥t (19.30%)
- ğŸ’° **Offer effectiveness**: Discount (18.28%) > BOGO (15.14%) > No Offer (10.62%)
- ğŸ“± **Channel**: Multichannel (17.17%) > Web (15.94%) > Phone (12.72%)
- ğŸŒ **Location**: Rural (18.81%) > Urban (13.90%) > Surburban (13.99%)
- â­ **High-value customers**: Chi tiÃªu >$325.66 cÃ³ conversion 18.30% vs 13.47% (regular)

**Outputs**:

- 4 visualization files (target distribution, conversion by categories, numerical analysis, correlation matrix)
- `eda_insights.txt` - BÃ¡o cÃ¡o chi tiáº¿t

---

### 2ï¸âƒ£ Feature Engineering

**File**: `notebooks/02_feature_engineering.py`

**27 features má»›i Ä‘Æ°á»£c táº¡o**:

#### A. RFM Analysis (4 features)

- `recency_score` (1-5): Äiá»ƒm recency
- `monetary_score` (1-5): Äiá»ƒm chi tiÃªu
- `rfm_score` (2-10): Tá»•ng Ä‘iá»ƒm RFM
- `customer_segment`: Champions/Loyal/Potential/At Risk/Lost

#### B. Behavioral Features (6 features)

- `promo_engagement` (0-1): Má»©c Ä‘á»™ tÆ°Æ¡ng tÃ¡c vá»›i promo
- `promo_variety` (0/1): ÄÃ£ dÃ¹ng nhiá»u loáº¡i promo
- `is_inactive`, `is_recent`: Flags hoáº¡t Ä‘á»™ng
- `is_high_value`, `is_low_value`: Flags giÃ¡ trá»‹

#### C. Interaction Features (7 features)

- `offer_channel`: TÆ°Æ¡ng tÃ¡c offer Ã— channel
- `referral_recent`: Referral Ã— recent activity
- `highvalue_discount`, `highvalue_bogo`: High-value Ã— promo type
- `location_channel`: Location Ã— channel
- `engagement_discount_offer`, `engagement_bogo_offer`: Engagement Ã— offer

#### D. Spending Features (3 features)

- `spending_per_day`: Chi tiÃªu trung bÃ¬nh má»—i ngÃ y
- `spending_category`: Low/Medium/High
- `history_log`: Log-transformed spending

#### E. Channel & Offer Features (5 features)

- `channel_score` (1-3): Äiá»ƒm channel
- `is_digital` (0/1): Digital channel flag
- `discount_match`, `bogo_match`, `offer_mismatch`: Offer matching

#### F. Location Features (2 features)

- `is_urban`, `is_rural`: Location flags

**Key Insights tá»« Feature Engineering**:

- ğŸ† **Champions segment**: 19.80% conversion (cao nháº¥t)
- ğŸš€ **is_recent**: +5.24% uplift
- ğŸ’ **is_high_value**: +4.83% uplift
- âœ¨ **offer matching**: Discount match +6.04%, BOGO match +4.63%

**Outputs**:

- `data/data_engineered.csv` (64,000 Ã— 36)
- `data/feature_list.txt`

---

### 3ï¸âƒ£ Data Preprocessing

**File**: `notebooks/03_preprocessing_pipeline.py`

**Quy trÃ¬nh**:

1. âœ‚ï¸ **Feature selection**: Drop 4 high-cardinality features â†’ 31 features
2. ğŸ”¢ **Encoding**: Label encoding cho 3 categorical features
3. ğŸ“Š **Train/Test split**: 80/20 stratified split (51,200 / 12,800)
4. âš–ï¸ **Scaling**: StandardScaler cho táº¥t cáº£ features
5. ğŸ¯ **SMOTE**: Balance training set tá»« 51,200 â†’ 87,370 samples (1:1 ratio)

**Outputs**:

- `data/X_train_balanced.csv`, `data/y_train_balanced.csv`
- `data/X_test.csv`, `data/y_test.csv`
- `models/scaler.pkl`, `models/label_encoders.pkl`
- `data/preprocessing_summary.txt`

---

### 4ï¸âƒ£ Model Training

**File**: `notebooks/04_model_training.py`

**5 models Ä‘Æ°á»£c train**:

1. Logistic Regression
2. Random Forest
3. Gradient Boosting
4. LightGBM
5. CatBoost

**Káº¿t quáº£ Performance**:

| Model                      | ROC-AUC    | Accuracy | Precision | Recall | F1-Score |
| -------------------------- | ---------- | -------- | --------- | ------ | -------- |
| **ğŸ† Logistic Regression** | **0.6535** | 0.6056   | 0.2126    | 0.6237 | 0.3171   |
| CatBoost                   | 0.6356     | 0.8220   | 0.2611    | 0.1160 | 0.1606   |
| Gradient Boosting          | 0.6343     | 0.8173   | 0.2478    | 0.1203 | 0.1619   |
| LightGBM                   | 0.6300     | 0.8137   | 0.2305    | 0.1150 | 0.1534   |
| Random Forest              | 0.6162     | 0.7602   | 0.2268    | 0.2629 | 0.2435   |

**Best Model**: Logistic Regression vá»›i ROC-AUC = **0.6535**

- âœ… **Improvement vs Baseline XGBoost (0.6344)**: +1.91 percentage points
- ğŸ¯ Recall cao (62.37%): PhÃ¡t hiá»‡n Ä‘Æ°á»£c nhiá»u khÃ¡ch hÃ ng tiá»m nÄƒng
- âš ï¸ Trade-off: Precision tháº¥p hÆ¡n cÃ¡c tree-based models

**Outputs**:

- 5 trained model files (.pkl)
- `models/best_model.pkl` (Logistic Regression)
- `results/model_comparison.csv`
- 4 visualization files (comparison, ROC curves, confusion matrices, feature importance)
- `results/training_summary.txt`

---

### 5ï¸âƒ£ Hyperparameter Tuning

**File**: `notebooks/05_model_optimization.py`

**Optimization method**: RandomizedSearchCV

- 30 iterations per model
- 5-fold cross-validation
- ROC-AUC scoring

**Káº¿t quáº£**:

| Model    | Baseline ROC-AUC | Optimized ROC-AUC | Improvement |
| -------- | ---------------- | ----------------- | ----------- |
| LightGBM | 0.6300           | 0.6438            | +1.39%      |
| CatBoost | 0.6356           | 0.6123            | -2.33%      |

**Best Optimized Model**: LightGBM (0.6438)

- Tuy nhiÃªn, **Logistic Regression baseline (0.6535)** váº«n lÃ  best overall

**Outputs**:

- `models/lightgbm_optimized.pkl`, `models/catboost_optimized.pkl`
- `models/final_best_model.pkl`
- `results/optimization_summary.txt`
- `results/optimization_comparison.csv`

---

### 6ï¸âƒ£ Business Strategy & ROI Analysis

**File**: `notebooks/06_business_strategy.py`

#### Business Assumptions:

- ğŸ’° Average order value: **150,000 VND**
- ğŸ“± Campaign cost per customer: **5,000 VND**
- ğŸ Average discount rate: **15%**
- ğŸ“Š Profit margin: **40%**

#### Optimal Strategy:

- ğŸ¯ **Prediction threshold**: 0.85
- ğŸ“ˆ **Expected ROI**: **2.83x** (282% return)
- ğŸ‘¥ **Customers to target**: 62 (tá»« 100,000 khÃ¡ch hÃ ng base)
- âœ… **Expected conversions**: 23
- ğŸ’¯ **Conversion rate**: 37.50%

#### Customer Segmentation:

| Segment      | Customers | Avg Probability | Conversion Rate | ROI      |
| ------------ | --------- | --------------- | --------------- | -------- |
| ğŸ”¥ Hot Lead  | 640       | 74.83%          | 28.91%          | 1.95x    |
| ğŸŸ¡ Warm Lead | 4,873     | 58.58%          | 20.25%          | 1.07x    |
| â„ï¸ Cold Lead | 5,882     | 40.65%          | 10.80%          | 0.10x    |
| â›” No Target | 1,405     | 24.50%          | 5.12%           | Negative |

#### Projected Business Impact:

**Monthly (100,000 customer base)**:

- ğŸ“ Target: 62 customers
- âœ… Conversions: 23
- ğŸ’µ Gross Revenue: **3.0M VND**
- ğŸ’¸ Campaign Cost: **0.3M VND**
- ğŸ’° Net Profit: **0.9M VND**
- ğŸ“Š ROI: **2.83x**

**Annual**:

- ğŸ“… Revenue: **35.9M VND**
- ğŸ’ Profit: **10.6M VND**

#### Targeting Strategies:

1. **ğŸ”¥ Hot Lead Campaign**: Target threshold â‰¥ 0.70 (highest ROI)
2. **â° Recency Win-Back**: Focus on customers with recency â‰¤ 3 days
3. **ğŸ’ VIP Appreciation**: Premium offers for high-value customers
4. **ğŸ“± Digital-First**: App-exclusive campaigns for digital users
5. **ğŸ¯ Personalized Matching**: Match offer type to historical preference

**Outputs**:

- `results/business_strategy.txt` (Full strategy document)
- `results/roi_analysis.csv`, `results/segment_analysis.csv`
- 2 visualization files (ROI curves, segment analysis)

---

## ğŸ“ˆ Káº¿t quáº£ Tá»•ng thá»ƒ

### Model Performance:

- âœ… **Best Model**: Logistic Regression
- ğŸ† **ROC-AUC**: 0.6535 (vÆ°á»£t baseline XGBoost 0.6344)
- ğŸ“Š **Improvement**: +1.91 percentage points (+3.0%)
- ğŸ¯ **Recall**: 62.37% (detect nhiá»u opportunities)

### Business Impact:

- ğŸ’° **ROI**: 2.83x (282% return)
- ğŸ“ˆ **Conversion lift**: 37.50% (á»Ÿ threshold optimal)
- ğŸ’µ **Annual profit projection**: 10.6M VND (vá»›i 100K customers)
- ğŸ¯ **Targeting efficiency**: 62 customers chá»‰ chiáº¿m 0.062% base nhÆ°ng Ä‘áº¡t ROI cao nháº¥t

### Key Success Factors:

1. âœ… **Feature Engineering**: RFM + Behavioral + Interaction features
2. âœ… **SMOTE**: Giáº£i quyáº¿t class imbalance
3. âœ… **Model Selection**: Logistic Regression surprisingly outperforms tree-based
4. âœ… **Business-driven threshold**: Tá»‘i Æ°u ROI thay vÃ¬ chá»‰ maximize accuracy

---

## ğŸ“ Cáº¥u trÃºc Project

```
promo-response2/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.csv                      # Dataset gá»‘c
â”‚   â”œâ”€â”€ data_engineered.csv           # Dataset sau feature engineering
â”‚   â”œâ”€â”€ X_train_balanced.csv          # Training set (SMOTE)
â”‚   â”œâ”€â”€ X_test.csv, y_test.csv        # Test set
â”‚   â”œâ”€â”€ feature_list.txt              # Danh sÃ¡ch features
â”‚   â””â”€â”€ preprocessing_summary.txt     # TÃ³m táº¯t preprocessing
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pkl                # Best overall model (Logistic Regression)
â”‚   â”œâ”€â”€ final_best_model.pkl          # Best optimized model (LightGBM)
â”‚   â”œâ”€â”€ logistic_regression.pkl       # Logistic Regression model
â”‚   â”œâ”€â”€ random_forest.pkl             # Random Forest model
â”‚   â”œâ”€â”€ gradient_boosting.pkl         # Gradient Boosting model
â”‚   â”œâ”€â”€ lightgbm.pkl, lightgbm_optimized.pkl
â”‚   â”œâ”€â”€ catboost.pkl, catboost_optimized.pkl
â”‚   â”œâ”€â”€ scaler.pkl                    # StandardScaler
â”‚   â”œâ”€â”€ label_encoders.pkl            # Label encoders
â”‚   â””â”€â”€ feature_names.pkl             # Feature names
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ eda_insights.txt              # EDA findings
â”‚   â”œâ”€â”€ model_comparison.csv          # Model performance comparison
â”‚   â”œâ”€â”€ training_summary.txt          # Training summary
â”‚   â”œâ”€â”€ optimization_summary.txt      # Optimization results
â”‚   â”œâ”€â”€ business_strategy.txt         # Business strategy document
â”‚   â”œâ”€â”€ roi_analysis.csv              # ROI by threshold
â”‚   â”œâ”€â”€ segment_analysis.csv          # Customer segmentation
â”‚   â””â”€â”€ *.png                         # Visualizations (11 files)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda_analysis.py            # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_feature_engineering.py     # Feature creation
â”‚   â”œâ”€â”€ 03_preprocessing_pipeline.py  # Data preprocessing
â”‚   â”œâ”€â”€ 04_model_training.py          # Model training
â”‚   â”œâ”€â”€ 05_model_optimization.py      # Hyperparameter tuning
â”‚   â””â”€â”€ 06_business_strategy.py       # Business recommendations
â”‚
â””â”€â”€ README.md                          # This file
```

---

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Requirements:

```bash
pip install pandas numpy scikit-learn lightgbm catboost imbalanced-learn matplotlib seaborn joblib
```

### Cháº¡y toÃ n bá»™ pipeline:

```bash
# BÆ°á»›c 1: EDA
python notebooks/01_eda_analysis.py

# BÆ°á»›c 2: Feature Engineering
python notebooks/02_feature_engineering.py

# BÆ°á»›c 3: Preprocessing
python notebooks/03_preprocessing_pipeline.py

# BÆ°á»›c 4: Model Training
python notebooks/04_model_training.py

# BÆ°á»›c 5: Hyperparameter Tuning (optional)
python notebooks/05_model_optimization.py

# BÆ°á»›c 6: Business Strategy
python notebooks/06_business_strategy.py
```

### Sá»­ dá»¥ng model Ä‘Ã£ train Ä‘á»ƒ predict:

```python
import joblib
import pandas as pd

# Load model vÃ  preprocessing tools
model = joblib.load('models/best_model.pkl')
scaler = joblib.load('models/scaler.pkl')
label_encoders = joblib.load('models/label_encoders.pkl')

# Load new data
new_data = pd.read_csv('new_customers.csv')

# Preprocess (apply feature engineering, encoding, scaling)
# ... (same steps as 02_feature_engineering.py vÃ  03_preprocessing_pipeline.py)

# Predict probability
predictions = model.predict_proba(new_data_processed)[:, 1]

# Apply optimal threshold
optimal_threshold = 0.85
should_target = predictions >= optimal_threshold

# Get customers to target
customers_to_target = new_data[should_target]
```

---

## ğŸ“Š Visualizations

### 1. Target Distribution

![Target Distribution](results/01_target_distribution.png)

### 2. Conversion by Categories

![Conversion by Categories](results/02_conversion_by_categories.png)

### 3. Model Comparison

![Model Comparison](results/model_comparison.png)

### 4. ROC Curves

![ROC Curves](results/roc_curves.png)

### 5. ROI Analysis

![ROI Analysis](results/roi_analysis.png)

### 6. Segment Analysis

![Segment Analysis](results/segment_analysis.png)

---

## ğŸ’¡ Key Insights & Recommendations

### Top Insights:

1. ğŸ¯ **Recency is King**: KhÃ¡ch hÃ ng mua gáº§n Ä‘Ã¢y (1-3 ngÃ y) cÃ³ conversion cao gáº¥p 1.65x
2. ğŸ’° **High-value matters**: Chi tiÃªu >Q3 ($325.66) cÃ³ conversion cao hÆ¡n 36%
3. ğŸ **Discount > BOGO**: Discount offer hiá»‡u quáº£ hÆ¡n BOGO 20.3%
4. ğŸ“± **Digital wins**: Web/Multichannel outperform Phone
5. ğŸŒ¾ **Rural opportunity**: Rural cÃ³ conversion cao nháº¥t (18.81%)

### Business Recommendations:

#### ğŸ¯ Immediate Actions:

1. **Target Hot Leads (threshold â‰¥ 0.70)**: 640 customers, ROI 1.95x
2. **Recency-based campaigns**: Focus trong 3 ngÃ y sau láº§n mua cuá»‘i
3. **Personalized offers**: Match vá»›i lá»‹ch sá»­ promo preference
4. **Digital-first strategy**: Prioritize Web/App channels

#### ğŸ“ˆ Long-term Strategy:

1. **Quarterly model retraining**: Capture seasonal patterns
2. **A/B testing framework**: Test different thresholds vÃ  offer types
3. **Customer journey optimization**: TÄƒng frequency Ä‘á»ƒ giá»¯ recency tháº¥p
4. **Segment-specific campaigns**: Different strategies cho Champions/Loyal/At Risk

#### âš ï¸ Risk Mitigation:

1. **Over-targeting**: Limit 2 campaigns/customer/month
2. **Discount fatigue**: Rotate offer types
3. **Model drift**: Monitor performance monthly
4. **ROI tracking**: Set up dashboard theo dÃµi real-time

---

## ğŸ“ Lessons Learned

### Technical:

1. âœ… **Feature engineering > Complex models**: RFM + Behavioral features quan trá»ng hÆ¡n deep models
2. âœ… **SMOTE works**: Cáº£i thiá»‡n recall tá»« ~8% lÃªn 62%
3. âœ… **Simple models can win**: Logistic Regression Ä‘Ã´i khi outperform tree-based
4. âš ï¸ **Class imbalance challenge**: 5.81:1 ratio khÃ³ handle, cáº§n nhiá»u techniques

### Business:

1. ğŸ’¡ **Threshold optimization crucial**: ROI optimization â‰  accuracy optimization
2. ğŸ’¡ **Segment-based targeting**: Hot/Warm/Cold cáº§n different strategies
3. ğŸ’¡ **Recency drives behavior**: Recent activity lÃ  predictor máº¡nh nháº¥t
4. ğŸ’¡ **ROI focus**: Model pháº£i align vá»›i business metrics, khÃ´ng chá»‰ ML metrics

---

## ğŸ“ Next Steps

### Phase 1: Validation (Week 1-2)

- [ ] Pilot test vá»›i 10% Hot Lead segment
- [ ] Collect actual conversion data
- [ ] Validate ROI predictions
- [ ] Adjust threshold if needed

### Phase 2: Scale (Week 3-4)

- [ ] Roll out to full Hot Lead segment
- [ ] Launch Warm Lead campaign
- [ ] A/B test different offer types
- [ ] Set up monitoring dashboard

### Phase 3: Optimize (Month 2-3)

- [ ] Collect 1-2 months real data
- [ ] Retrain model with actual conversions
- [ ] Fine-tune thresholds per segment
- [ ] Implement feedback loop

### Phase 4: Advanced Features (Month 4+)

- [ ] Add time-series features (seasonality, day of week)
- [ ] Implement customer lifetime value prediction
- [ ] Build uplift models (incremental effect)
- [ ] Develop dynamic threshold adjustment

---

## ğŸ‘¥ Team & Contact

**Data Science Team**

- **Project**: Promotional Response Prediction
- **Industry**: F&B (Coffee Shop)
- **Model**: Logistic Regression (ROC-AUC 0.6535)
- **Deployment Date**: November 2025

**For questions or support**:

- ğŸ“§ Email: datascience@coffeeshop.com
- ğŸ“ Phone: (xxx) xxx-xxxx
- ğŸ“ Repository: github.com/coffeeshop/promo-response2

---

## ğŸ“š References

### Papers & Articles:

1. SMOTE: Synthetic Minority Over-sampling Technique (Chawla et al., 2002)
2. RFM Analysis for Customer Segmentation
3. Uplift Modeling for Causal Inference in Marketing

### Libraries Used:

- scikit-learn 1.7.2
- pandas 2.3.3
- numpy 2.2.6
- lightgbm 4.6.0
- catboost 1.2.8
- imbalanced-learn 0.14.0
- matplotlib 3.10.7
- seaborn (latest)

---

## â­ Project Highlights

- âœ… **Production-ready pipeline**: End-to-end automation
- âœ… **Business-driven**: Focus on ROI, not just accuracy
- âœ… **Comprehensive documentation**: Full reports vÃ  visualizations
- âœ… **Actionable insights**: Clear targeting strategies
- âœ… **Scalable architecture**: Easy to retrain vÃ  deploy

---

## ğŸ“„ License

This project is proprietary to Coffee Shop. All rights reserved.

---

**Last Updated**: November 18, 2025
**Version**: 1.0.0
**Status**: âœ… Production Ready
