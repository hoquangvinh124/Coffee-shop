{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b333ab",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from utils import *\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "data_dir = Path('../data/processed')\n",
    "X_train = pd.read_csv(data_dir / 'X_train.csv')\n",
    "y_train = pd.read_csv(data_dir / 'y_train.csv').values.ravel()\n",
    "X_test = pd.read_csv(data_dir / 'X_test.csv')\n",
    "y_test = pd.read_csv(data_dir / 'y_test.csv').values.ravel()\n",
    "\n",
    "# Combine for temporal splitting\n",
    "X_full = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
    "y_full = np.concatenate([y_train, y_test])\n",
    "\n",
    "print(f\"Full dataset shape: {X_full.shape}\")\n",
    "print(f\"Features: {list(X_full.columns)}\")\n",
    "print(f\"\\nTarget distribution:\\n{pd.Series(y_full).value_counts().sort_index()}\")\n",
    "\n",
    "# Class names\n",
    "class_names = {\n",
    "    0: 'Offer Received',\n",
    "    1: 'Offer Viewed',\n",
    "    2: 'Transaction',\n",
    "    3: 'Offer Completed'\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ“ Loaded {len(X_full)} total samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c47b5",
   "metadata": {},
   "source": [
    "## 2. Temporal Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29258d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze reg_month distribution\n",
    "if 'reg_month' in X_full.columns:\n",
    "    reg_month_stats = X_full['reg_month'].describe()\n",
    "    print(\"\\nðŸ“Š Registration Month Statistics:\")\n",
    "    print(reg_month_stats)\n",
    "    \n",
    "    # Visualize distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(X_full['reg_month'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(X_full['reg_month'].quantile(0.6), color='red', linestyle='--', linewidth=2, label='60% (Train cutoff)')\n",
    "    axes[0].axvline(X_full['reg_month'].quantile(0.8), color='orange', linestyle='--', linewidth=2, label='80% (Val cutoff)')\n",
    "    axes[0].set_xlabel('Registration Month (Normalized)', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0].set_title('Registration Month Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Cumulative distribution\n",
    "    sorted_months = np.sort(X_full['reg_month'])\n",
    "    cumulative = np.arange(1, len(sorted_months) + 1) / len(sorted_months) * 100\n",
    "    axes[1].plot(sorted_months, cumulative, linewidth=2)\n",
    "    axes[1].axhline(60, color='red', linestyle='--', linewidth=2, label='60% Train')\n",
    "    axes[1].axhline(80, color='orange', linestyle='--', linewidth=2, label='80% Val')\n",
    "    axes[1].set_xlabel('Registration Month (Normalized)', fontsize=12)\n",
    "    axes[1].set_ylabel('Cumulative %', fontsize=12)\n",
    "    axes[1].set_title('Cumulative Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    figures_dir = Path('../results/figures')\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(figures_dir / 'temporal_reg_month_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ“ Saved to results/figures/temporal_reg_month_distribution.png\")\n",
    "else:\n",
    "    print(\"\\nâš  Warning: 'reg_month' column not found in data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c30b4",
   "metadata": {},
   "source": [
    "## 3. Create Temporal Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ad44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal splits based on reg_month percentiles\n",
    "if 'reg_month' in X_full.columns:\n",
    "    # Calculate split points (60% train, 20% val, 20% test)\n",
    "    train_cutoff = X_full['reg_month'].quantile(0.6)\n",
    "    val_cutoff = X_full['reg_month'].quantile(0.8)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š TEMPORAL SPLIT STRATEGY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Train cutoff (60%): reg_month <= {train_cutoff:.4f}\")\n",
    "    print(f\"Val cutoff (80%): {train_cutoff:.4f} < reg_month <= {val_cutoff:.4f}\")\n",
    "    print(f\"Test: reg_month > {val_cutoff:.4f}\")\n",
    "    \n",
    "    # Create splits\n",
    "    train_mask = X_full['reg_month'] <= train_cutoff\n",
    "    val_mask = (X_full['reg_month'] > train_cutoff) & (X_full['reg_month'] <= val_cutoff)\n",
    "    test_mask = X_full['reg_month'] > val_cutoff\n",
    "    \n",
    "    # Split data\n",
    "    X_train_temporal = X_full[train_mask].reset_index(drop=True)\n",
    "    y_train_temporal = y_full[train_mask]\n",
    "    \n",
    "    X_val_temporal = X_full[val_mask].reset_index(drop=True)\n",
    "    y_val_temporal = y_full[val_mask]\n",
    "    \n",
    "    X_test_temporal = X_full[test_mask].reset_index(drop=True)\n",
    "    y_test_temporal = y_full[test_mask]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Split Sizes:\")\n",
    "    print(f\"Training: {len(X_train_temporal):,} samples ({len(X_train_temporal)/len(X_full)*100:.1f}%)\")\n",
    "    print(f\"Validation: {len(X_val_temporal):,} samples ({len(X_val_temporal)/len(X_full)*100:.1f}%)\")\n",
    "    print(f\"Test: {len(X_test_temporal):,} samples ({len(X_test_temporal)/len(X_full)*100:.1f}%)\")\n",
    "    \n",
    "    # Check class distributions\n",
    "    print(f\"\\nðŸ“Š Class Distribution Comparison:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for class_id, class_name in class_names.items():\n",
    "        train_pct = (y_train_temporal == class_id).sum() / len(y_train_temporal) * 100\n",
    "        val_pct = (y_val_temporal == class_id).sum() / len(y_val_temporal) * 100\n",
    "        test_pct = (y_test_temporal == class_id).sum() / len(y_test_temporal) * 100\n",
    "        \n",
    "        print(f\"{class_name:20s}: Train={train_pct:5.2f}%, Val={val_pct:5.2f}%, Test={test_pct:5.2f}%\")\n",
    "    \n",
    "    print(\"\\nâœ“ Temporal splits created successfully\")\n",
    "else:\n",
    "    print(\"\\nâš  Cannot create temporal splits without 'reg_month' column\")\n",
    "    X_train_temporal = X_train\n",
    "    y_train_temporal = y_train\n",
    "    X_val_temporal = X_test[:len(X_test)//2]\n",
    "    y_val_temporal = y_test[:len(y_test)//2]\n",
    "    X_test_temporal = X_test[len(X_test)//2:]\n",
    "    y_test_temporal = y_test[len(y_test)//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62728aaf",
   "metadata": {},
   "source": [
    "## 4. Train Models on Temporal Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c64b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost on temporal data\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ðŸŽ¯ Training XGBoost on Temporal Split\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "xgb_temporal = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_temporal.fit(\n",
    "    X_train_temporal, \n",
    "    y_train_temporal,\n",
    "    eval_set=[(X_val_temporal, y_val_temporal)],\n",
    "    verbose=False\n",
    ")\n",
    "print(\"âœ“ XGBoost training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest on temporal data\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ðŸŽ¯ Training Random Forest on Temporal Split\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "rf_temporal = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf_temporal.fit(X_train_temporal, y_train_temporal)\n",
    "print(\"âœ“ Random Forest training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7e8cd",
   "metadata": {},
   "source": [
    "## 5. Evaluate Temporal Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on all splits\n",
    "temporal_results = []\n",
    "\n",
    "models = {\n",
    "    'XGBoost Temporal': xgb_temporal,\n",
    "    'Random Forest Temporal': rf_temporal\n",
    "}\n",
    "\n",
    "splits = {\n",
    "    'Train': (X_train_temporal, y_train_temporal),\n",
    "    'Validation': (X_val_temporal, y_val_temporal),\n",
    "    'Test (Future)': (X_test_temporal, y_test_temporal)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ðŸ“Š {model_name} - Temporal Evaluation\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for split_name, (X_split, y_split) in splits.items():\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_split)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(y_split, y_pred)\n",
    "        f1_micro = f1_score(y_split, y_pred, average='micro')\n",
    "        f1_macro = f1_score(y_split, y_pred, average='macro')\n",
    "        f1_weighted = f1_score(y_split, y_pred, average='weighted')\n",
    "        \n",
    "        temporal_results.append({\n",
    "            'Model': model_name,\n",
    "            'Split': split_name,\n",
    "            'Samples': len(X_split),\n",
    "            'Accuracy': accuracy,\n",
    "            'F1_Micro': f1_micro,\n",
    "            'F1_Macro': f1_macro,\n",
    "            'F1_Weighted': f1_weighted\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{split_name} ({len(X_split):,} samples):\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  F1 (Micro): {f1_micro:.4f}\")\n",
    "        print(f\"  F1 (Macro): {f1_macro:.4f}\")\n",
    "        print(f\"  F1 (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "temporal_results_df = pd.DataFrame(temporal_results)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ðŸ“Š TEMPORAL VALIDATION RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "display(temporal_results_df.round(4))\n",
    "\n",
    "# Save results\n",
    "output_dir = Path('../results/metrics')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "temporal_results_df.to_csv(output_dir / 'temporal_validation_results.csv', index=False)\n",
    "print(\"\\nâœ“ Saved to results/metrics/temporal_validation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance degradation over time\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "metrics_to_plot = ['F1_Weighted', 'F1_Macro']\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    pivot_data = temporal_results_df.pivot(index='Split', columns='Model', values=metric)\n",
    "    pivot_data = pivot_data.reindex(['Train', 'Validation', 'Test (Future)'])\n",
    "    \n",
    "    pivot_data.plot(kind='bar', ax=axes[idx], width=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(f'{metric} Across Temporal Splits', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Data Split', fontsize=12)\n",
    "    axes[idx].set_ylabel(metric, fontsize=12)\n",
    "    axes[idx].legend(title='Model', loc='best')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    axes[idx].set_ylim(0, 1.0)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'temporal_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved to results/figures/temporal_performance_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958c9a6",
   "metadata": {},
   "source": [
    "## 6. Analyze Performance Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbe0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance degradation from train to test\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ðŸ“‰ PERFORMANCE DEGRADATION ANALYSIS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "degradation_results = []\n",
    "\n",
    "for model_name in temporal_results_df['Model'].unique():\n",
    "    model_data = temporal_results_df[temporal_results_df['Model'] == model_name]\n",
    "    \n",
    "    train_row = model_data[model_data['Split'] == 'Train'].iloc[0]\n",
    "    test_row = model_data[model_data['Split'] == 'Test (Future)'].iloc[0]\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    for metric in ['Accuracy', 'F1_Micro', 'F1_Macro', 'F1_Weighted']:\n",
    "        train_val = train_row[metric]\n",
    "        test_val = test_row[metric]\n",
    "        degradation = train_val - test_val\n",
    "        degradation_pct = (degradation / train_val * 100) if train_val > 0 else 0\n",
    "        \n",
    "        print(f\"  {metric:15s}: Train={train_val:.4f}, Test={test_val:.4f}, \"\n",
    "              f\"Î”={degradation:.4f} ({degradation_pct:.2f}%)\")\n",
    "        \n",
    "        degradation_results.append({\n",
    "            'Model': model_name,\n",
    "            'Metric': metric,\n",
    "            'Train': train_val,\n",
    "            'Test': test_val,\n",
    "            'Degradation': degradation,\n",
    "            'Degradation_%': degradation_pct\n",
    "        })\n",
    "\n",
    "# Save degradation analysis\n",
    "degradation_df = pd.DataFrame(degradation_results)\n",
    "degradation_df.to_csv(output_dir / 'temporal_degradation_analysis.csv', index=False)\n",
    "print(\"\\nâœ“ Saved to results/metrics/temporal_degradation_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc870f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize degradation\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Filter for F1_Weighted metric\n",
    "f1_degradation = degradation_df[degradation_df['Metric'] == 'F1_Weighted']\n",
    "\n",
    "x = np.arange(len(f1_degradation))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, f1_degradation['Train'], width, label='Train', color='green', edgecolor='black')\n",
    "bars2 = ax.bar(x + width/2, f1_degradation['Test'], width, label='Test (Future)', color='red', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('F1-Score (Weighted)', fontsize=12)\n",
    "ax.set_title('Train vs Test Performance (Temporal Validation)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(f1_degradation['Model'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim(0, 1.0)\n",
    "\n",
    "# Add degradation percentages\n",
    "for i, (idx, row) in enumerate(f1_degradation.iterrows()):\n",
    "    ax.text(i, max(row['Train'], row['Test']) + 0.02, \n",
    "            f\"-{abs(row['Degradation_%']):.1f}%\",\n",
    "            ha='center', fontsize=10, color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'temporal_degradation_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved to results/figures/temporal_degradation_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84eb0e",
   "metadata": {},
   "source": [
    "## 7. Compare with Original Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original models for comparison\n",
    "models_dir = Path('../models')\n",
    "original_models = {}\n",
    "\n",
    "try:\n",
    "    original_models['XGBoost Original'] = joblib.load(models_dir / 'xgboost_model.pkl')\n",
    "    print(\"âœ“ Loaded original XGBoost\")\n",
    "except:\n",
    "    print(\"âœ— Could not load original XGBoost\")\n",
    "\n",
    "try:\n",
    "    original_models['Random Forest Original'] = joblib.load(models_dir / 'random_forest_model.pkl')\n",
    "    print(\"âœ“ Loaded original Random Forest\")\n",
    "except:\n",
    "    print(\"âœ— Could not load original Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs temporal models on future test set\n",
    "if original_models:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ“Š ORIGINAL vs TEMPORAL MODELS ON FUTURE DATA\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    # Temporal models\n",
    "    for model_name, model in [('XGBoost Temporal', xgb_temporal), ('Random Forest Temporal', rf_temporal)]:\n",
    "        y_pred = model.predict(X_test_temporal)\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'Model': model_name,\n",
    "            'Type': 'Temporal',\n",
    "            'Accuracy': accuracy_score(y_test_temporal, y_pred),\n",
    "            'F1_Weighted': f1_score(y_test_temporal, y_pred, average='weighted'),\n",
    "            'F1_Macro': f1_score(y_test_temporal, y_pred, average='macro')\n",
    "        })\n",
    "    \n",
    "    # Original models\n",
    "    for model_name, model in original_models.items():\n",
    "        y_pred = model.predict(X_test_temporal)\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'Model': model_name,\n",
    "            'Type': 'Original',\n",
    "            'Accuracy': accuracy_score(y_test_temporal, y_pred),\n",
    "            'F1_Weighted': f1_score(y_test_temporal, y_pred, average='weighted'),\n",
    "            'F1_Macro': f1_score(y_test_temporal, y_pred, average='macro')\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    display(comparison_df.round(4))\n",
    "    \n",
    "    # Save comparison\n",
    "    comparison_df.to_csv(output_dir / 'temporal_vs_original_comparison.csv', index=False)\n",
    "    print(\"\\nâœ“ Saved to results/metrics/temporal_vs_original_comparison.csv\")\n",
    "    \n",
    "    # Visualize comparison\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Group by model type\n",
    "    x = np.arange(len(comparison_df))\n",
    "    width = 0.25\n",
    "    \n",
    "    bars1 = ax.bar(x - width, comparison_df['Accuracy'], width, label='Accuracy', edgecolor='black')\n",
    "    bars2 = ax.bar(x, comparison_df['F1_Weighted'], width, label='F1 Weighted', edgecolor='black')\n",
    "    bars3 = ax.bar(x + width, comparison_df['F1_Macro'], width, label='F1 Macro', edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel('Model', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title('Original vs Temporal Models on Future Test Data', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"{row['Model']}\\n({row['Type']})\" for _, row in comparison_df.iterrows()], \n",
    "                        rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'original_vs_temporal_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ Saved to results/figures/original_vs_temporal_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313a7fc",
   "metadata": {},
   "source": [
    "## 8. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943013d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "summary_lines = [\n",
    "    \"\\n\" + \"=\"*80,\n",
    "    \"ðŸ“Š TEMPORAL VALIDATION SUMMARY\",\n",
    "    \"=\"*80,\n",
    "    \"\",\n",
    "    \"1. DATA SPLITS:\",\n",
    "    f\"   Training: {len(X_train_temporal):,} samples (early customers)\",\n",
    "    f\"   Validation: {len(X_val_temporal):,} samples (mid-period customers)\",\n",
    "    f\"   Test: {len(X_test_temporal):,} samples (recent/future customers)\",\n",
    "    \"\",\n",
    "    \"2. TEMPORAL MODEL PERFORMANCE:\",\n",
    "]\n",
    "\n",
    "for model_name in ['XGBoost Temporal', 'Random Forest Temporal']:\n",
    "    model_results = temporal_results_df[temporal_results_df['Model'] == model_name]\n",
    "    test_row = model_results[model_results['Split'] == 'Test (Future)'].iloc[0]\n",
    "    \n",
    "    summary_lines.append(f\"\\n   {model_name}:\")\n",
    "    summary_lines.append(f\"     Accuracy: {test_row['Accuracy']:.4f}\")\n",
    "    summary_lines.append(f\"     F1 (Weighted): {test_row['F1_Weighted']:.4f}\")\n",
    "    summary_lines.append(f\"     F1 (Macro): {test_row['F1_Macro']:.4f}\")\n",
    "\n",
    "summary_lines.extend([\n",
    "    \"\",\n",
    "    \"3. PERFORMANCE DEGRADATION:\",\n",
    "])\n",
    "\n",
    "for model_name in ['XGBoost Temporal', 'Random Forest Temporal']:\n",
    "    model_deg = degradation_df[\n",
    "        (degradation_df['Model'] == model_name) & \n",
    "        (degradation_df['Metric'] == 'F1_Weighted')\n",
    "    ].iloc[0]\n",
    "    \n",
    "    summary_lines.append(\n",
    "        f\"   {model_name}: {model_deg['Degradation_%']:.2f}% drop from train to test\"\n",
    "    )\n",
    "\n",
    "if original_models:\n",
    "    summary_lines.extend([\n",
    "        \"\",\n",
    "        \"4. ORIGINAL vs TEMPORAL COMPARISON:\",\n",
    "    ])\n",
    "    \n",
    "    for model_type in ['XGBoost', 'Random Forest']:\n",
    "        temporal_name = f\"{model_type} Temporal\"\n",
    "        original_name = f\"{model_type} Original\"\n",
    "        \n",
    "        if temporal_name in comparison_df['Model'].values and original_name in comparison_df['Model'].values:\n",
    "            temporal_f1 = comparison_df[comparison_df['Model'] == temporal_name]['F1_Weighted'].iloc[0]\n",
    "            original_f1 = comparison_df[comparison_df['Model'] == original_name]['F1_Weighted'].iloc[0]\n",
    "            diff = temporal_f1 - original_f1\n",
    "            \n",
    "            summary_lines.append(\n",
    "                f\"   {model_type}: Temporal F1={temporal_f1:.4f}, Original F1={original_f1:.4f}, \"\n",
    "                f\"Î”={diff:+.4f}\"\n",
    "            )\n",
    "\n",
    "summary_lines.extend([\n",
    "    \"\",\n",
    "    \"5. KEY FINDINGS:\",\n",
    "    f\"   - Models trained on temporal splits show realistic future performance\",\n",
    "    f\"   - Performance degradation ranges from {degradation_df['Degradation_%'].min():.2f}% to {degradation_df['Degradation_%'].max():.2f}%\",\n",
    "    f\"   - {'Temporal models perform better' if comparison_df[comparison_df['Type']=='Temporal']['F1_Weighted'].mean() > comparison_df[comparison_df['Type']=='Original']['F1_Weighted'].mean() else 'Original models perform better'} on future data\",\n",
    "    \"\",\n",
    "    \"6. RECOMMENDATIONS:\",\n",
    "    \"   âœ“ Use temporal validation for more realistic performance estimates\",\n",
    "    \"   âœ“ Retrain models periodically as new data becomes available\",\n",
    "    \"   âœ“ Monitor performance degradation in production\",\n",
    "    \"   âœ“ Consider online learning or incremental updates\",\n",
    "    \"   âœ“ Implement model retraining triggers based on performance thresholds\",\n",
    "    \"\",\n",
    "    \"=\"*80,\n",
    "    \"âœ“ TEMPORAL VALIDATION COMPLETE\",\n",
    "    \"=\"*80\n",
    "])\n",
    "\n",
    "summary_text = \"\\n\".join(summary_lines)\n",
    "print(summary_text)\n",
    "\n",
    "# Save summary\n",
    "with open(output_dir / 'temporal_validation_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"\\nâœ“ Saved summary to results/metrics/temporal_validation_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9812b6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook performed temporal validation to assess model performance on future data:\n",
    "\n",
    "âœ… **Temporal Splits**: Created time-based train/validation/test splits using reg_month\n",
    "\n",
    "âœ… **Model Training**: Trained XGBoost and Random Forest on temporal data\n",
    "\n",
    "âœ… **Performance Analysis**: Evaluated degradation from training to future test data\n",
    "\n",
    "âœ… **Comparison**: Compared temporal models with original random-split models\n",
    "\n",
    "**Key Insight**: Temporal validation provides more realistic estimates of production performance compared to random splits.\n",
    "\n",
    "**Next Steps**:\n",
    "1. Implement continuous monitoring in production\n",
    "2. Set up automated retraining pipelines\n",
    "3. Use A/B testing to validate improvements"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
