"""
Demo: T·∫°i sao R¬≤ √¢m trong Time Series Forecasting
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# T·∫°o data gi·ªëng coffee shop (c√≥ strong upward trend)
dates = pd.date_range('2023-01-01', periods=20, freq='D')
# Revenue tƒÉng m·∫°nh theo th·ªùi gian (gi·ªëng +124% growth)
actual_revenue = np.array([
    3000, 3100, 3200, 3300, 3400,  # Tu·∫ßn 1
    3500, 3600, 3700, 3800, 3900,  # Tu·∫ßn 2
    4000, 4100, 4200, 4300, 4400,  # Tu·∫ßn 3
    4500, 4600, 4700, 4800, 4900   # Tu·∫ßn 4 (test set)
])

# Train/test split
train_actual = actual_revenue[:15]  # 15 ng√†y ƒë·∫ßu
test_actual = actual_revenue[15:]   # 5 ng√†y cu·ªëi

print("="*70)
print(" T·∫†I SAO R¬≤ √ÇM TRONG TIME SERIES?")
print("="*70)

# Baseline: Predict b·∫±ng TRUNG B√åNH training set
baseline_mean = train_actual.mean()
baseline_predictions = np.array([baseline_mean] * len(test_actual))

print(f"\n1. BASELINE (predict b·∫±ng trung b√¨nh train):")
print(f"   Training mean: ${baseline_mean:,.2f}")
print(f"   Predictions: T·∫•t c·∫£ = ${baseline_mean:,.2f}")

# Model predictions (v√≠ d·ª• model kh√¥ng t·ªët, overfit)
# Gi·∫£ s·ª≠ model predict th·∫•p h∆°n actual
model_predictions = test_actual - 300  # Model systematically underpredict

print(f"\n2. MODEL PREDICTIONS:")
for i, (actual, pred) in enumerate(zip(test_actual, model_predictions)):
    print(f"   Day {i+1}: Actual ${actual:,} | Predicted ${pred:,} | Error ${actual-pred:,}")

# Calculate R¬≤
from sklearn.metrics import r2_score, mean_squared_error

r2_model = r2_score(test_actual, model_predictions)
r2_baseline = r2_score(test_actual, baseline_predictions)

mse_model = mean_squared_error(test_actual, model_predictions)
mse_baseline = mean_squared_error(test_actual, baseline_predictions)

print(f"\n{'='*70}")
print(" K·∫æT QU·∫¢:")
print(f"{'='*70}")
print(f"\nMODEL:")
print(f"  MSE:  {mse_model:,.2f}")
print(f"  R¬≤:   {r2_model:.4f}  {'‚Üê √ÇM!' if r2_model < 0 else ''}")

print(f"\nBASELINE (trung b√¨nh):")
print(f"  MSE:  {mse_baseline:,.2f}")
print(f"  R¬≤:   {r2_baseline:.4f}")

print(f"\n{'='*70}")
print(" GI·∫¢I TH√çCH:")
print(f"{'='*70}")
print(f"""
R¬≤ = 1 - (MSE_model / MSE_baseline)
R¬≤ = 1 - ({mse_model:,.2f} / {mse_baseline:,.2f})
R¬≤ = 1 - {mse_model/mse_baseline:.4f}
R¬≤ = {r2_model:.4f}

‚û°Ô∏è R¬≤ √ÇM nghƒ©a l√†: MSE_model > MSE_baseline
‚û°Ô∏è Model d·ª± ƒëo√°n T·ªÜ H∆†N d·ª± ƒëo√°n b·∫±ng trung b√¨nh!
""")

# Visualize
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Predictions comparison
x = range(len(test_actual))
axes[0].plot(x, test_actual, 'ko-', linewidth=3, markersize=8, label='Actual', zorder=3)
axes[0].plot(x, baseline_predictions, 'b--', linewidth=2, marker='s', markersize=6,
             label=f'Baseline (mean=${baseline_mean:.0f})', alpha=0.7)
axes[0].plot(x, model_predictions, 'r--', linewidth=2, marker='^', markersize=6,
             label='Model Predictions', alpha=0.7)
axes[0].set_xlabel('Test Day', fontsize=11)
axes[0].set_ylabel('Revenue ($)', fontsize=11)
axes[0].set_title('Why R¬≤ is Negative', fontsize=12, fontweight='bold')
axes[0].legend()
axes[0].grid(alpha=0.3)

# Plot 2: Errors comparison
baseline_errors = np.abs(test_actual - baseline_predictions)
model_errors = np.abs(test_actual - model_predictions)

axes[1].bar(x, baseline_errors, alpha=0.6, label='Baseline Errors', color='blue')
axes[1].bar(x, model_errors, alpha=0.6, label='Model Errors', color='red')
axes[1].set_xlabel('Test Day', fontsize=11)
axes[1].set_ylabel('Absolute Error ($)', fontsize=11)
axes[1].set_title('Error Comparison', fontsize=12, fontweight='bold')
axes[1].legend()
axes[1].grid(alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('r2_negative_explanation.png', dpi=150, bbox_inches='tight')
plt.show()

print("\n‚úì Visualization saved to r2_negative_explanation.png")

# Coffee shop case
print(f"\n{'='*70}")
print(" √ÅP D·ª§NG V√ÄO COFFEE SHOP PROJECT:")
print(f"{'='*70}")
print("""
Coffee shop revenue c√≥ STRONG UPWARD TREND (+124% growth):
- Jan: ~$2,400/day
- Jun: ~$5,400/day

Test set: Nh·ªØng ng√†y cu·ªëi Jun v·ªõi revenue cao (~$5,500-6,400)
Training mean: ~$3,860

N·∫øu predict b·∫±ng training mean ($3,860):
‚Üí Sai r·∫•t nhi·ªÅu! V√¨ Jun cao h∆°n nhi·ªÅu

Model predictions c≈©ng sai nh∆∞ng KH√îNG S√ÅI B·∫∞NG baseline
‚Üí R¬≤ v·∫´n √¢m nh∆∞ng model V·∫™N T·ªêT H∆†N baseline!

üìä Ch√∫ √Ω metrics quan tr·ªçng h∆°n:
   - MAPE: 6.68% (MA_3) ‚Üê ƒê√¢y l√† metric t·ªët!
   - RMSE: $468 (MA_3) ‚Üê ƒê√¢y c≈©ng t·ªët!
   - R¬≤ √¢m: Kh√¥ng sao, v√¨ baseline (mean) qu√° t·ªá v·ªõi trending data
""")

print(f"\n{'='*70}")
print(" K·∫æT LU·∫¨N:")
print(f"{'='*70}")
print("""
‚úì R¬≤ √ÇM KH√îNG c√≥ nghƒ©a l√† model T·ªÜ!
‚úì N√≥ ch·ªâ nghƒ©a l√† model t·ªá h∆°n "predict b·∫±ng trung b√¨nh"
‚úì V·ªõi time series c√≥ trend m·∫°nh, "predict b·∫±ng trung b√¨nh" l√† baseline T·ªÜ
‚úì ‚Üí R¬≤ kh√¥ng ph·∫£i metric t·ªët cho time series c√≥ trend!

üìå N√™n d√πng metrics n√†y thay th·∫ø:
   1. MAPE (Mean Absolute Percentage Error) ‚Üê BEST
   2. RMSE (Root Mean Squared Error)
   3. MAE (Mean Absolute Error)
   4. MBD (Mean Bias Deviation) - check systematic error
""")
