# ğŸ“Š ÄÃNH GIÃ MODEL MACHINE LEARNING - BÃO CÃO CHUYÃŠN GIA

**Dá»± Ã¡n**: Promotional Response Prediction - Coffee Shop  
**NgÃ y Ä‘Ã¡nh giÃ¡**: 18/11/2025  
**NgÆ°á»i Ä‘Ã¡nh giÃ¡**: ML Expert (20 nÄƒm kinh nghiá»‡m)  
**Model Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡**: XGBoost, Gradient Boosting, Random Forest

---

## ğŸš€ Tá»”NG QUAN

### BÃ i ToÃ¡n

- **Loáº¡i**: Binary Classification (Dá»± Ä‘oÃ¡n conversion)
- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng cÃ³ mua hÃ ng sau khi nháº­n promotional offer hay khÃ´ng
- **Target**: `conversion` (0 = No Purchase, 1 = Purchase)
- **Dataset**:
  - Training: 87,370 samples (SMOTE balanced 50-50)
  - Test: 12,800 samples (imbalanced ~14.7% positive class)
  - Features: 23 (sau encoding vÃ  feature engineering)

### Models ÄÃ£ Train

1. **XGBoost** â­ (Best Model)
   - Hyperparameters: learning_rate=0.1, max_depth=5, n_estimators=200, colsample_bytree=0.8, subsample=0.8
2. **Gradient Boosting**

   - Hyperparameters: learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0

3. **Random Forest**
   - Hyperparameters: n_estimators=200, max_depth=None, min_samples_split=2, min_samples_leaf=1

### Training Process

- **Method**: GridSearchCV vá»›i 5-fold Cross-Validation
- **Class Balancing**: SMOTE (Synthetic Minority Over-sampling Technique)
- **Preprocessing**: StandardScaler + OneHotEncoder
- **Train/Test Split**: 80/20 stratified

---

## ğŸ“Š PERFORMANCE - ÄÃNH GIÃ CHI TIáº¾T

### 1. Performance Tá»•ng Quan (Threshold = 0.5)

| Model             | ROC-AUC    | Accuracy   | F1-Score   | Precision  | Recall     |
| ----------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| **XGBoost**       | **0.6344** | **85.31%** | **0.0011** | **0.0057** | **0.0006** |
| Gradient Boosting | 0.6341     | 85.27%     | 0.0011     | 0.0057     | 0.0006     |
| Random Forest     | 0.5900     | 82.89%     | 0.0759     | 0.5000     | 0.0412     |

**Nháº­n xÃ©t ban Ä‘áº§u**:

- âœ… ROC-AUC tá»‘t (0.6344) - model cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t class
- âœ… Accuracy cao (85.31%)
- âš ï¸ F1-Score cá»±c ká»³ tháº¥p (0.0011) - **RED FLAG**
- âš ï¸ Precision vÃ  Recall gáº§n nhÆ° báº±ng 0

**Giáº£i thÃ­ch**: MÃ¢u thuáº«n giá»¯a accuracy cao vÃ  F1 tháº¥p cho tháº¥y model Ä‘ang bá»‹ **dominated by majority class** - dá»± Ä‘oÃ¡n háº§u háº¿t lÃ  class 0 (No Purchase).

---

### 2. Confusion Matrix - XGBoost Model

#### Threshold = 0.5 (Default)

```
                    Predicted
                No Purchase (0)    Purchase (1)
Actual  No (0)     10,915 (99.98%)    7 (0.02%)
        Yes (1)     1,867 (99.36%)    11 (0.64%)

Total: 12,800 samples
```

**PhÃ¢n tÃ­ch tá»«ng cell**:

- **True Negatives (TN): 10,915** - Model dá»± Ä‘oÃ¡n Ä‘Ãºng 99.98% class 0 âœ…
- **False Positives (FP): 7** - Model hiáº¿m khi nháº§m class 0 thÃ nh class 1 âœ…
- **False Negatives (FN): 1,867** - Model bá» sÃ³t 99.36% class 1 âŒâŒâŒ
- **True Positives (TP): 11** - Model chá»‰ báº¯t Ä‘Æ°á»£c 0.64% class 1 âŒâŒâŒ

**Metrics chi tiáº¿t**:

- **Specificity** (True Negative Rate): 99.98% - Dá»± Ä‘oÃ¡n class 0 cá»±c ká»³ tá»‘t
- **Sensitivity/Recall** (True Positive Rate): **0.64%** - Dá»± Ä‘oÃ¡n class 1 cá»±c ká»³ tá»‡
- **False Positive Rate**: 0.02% - Ráº¥t tháº¥p
- **False Negative Rate**: **99.36%** - Cá»±c ká»³ cao (bá» sÃ³t háº§u háº¿t converter)

---

### 3. Performance Tá»«ng Class

#### Class 0 (No Purchase) - **Lá»šP Máº NH** ğŸ’ª

- **Precision**: N/A (model dá»± Ä‘oÃ¡n háº§u háº¿t lÃ  class 0, khÃ´ng cÃ³ Ã½ nghÄ©a)
- **Recall**: 99.98% - Báº¯t Ä‘Æ°á»£c háº§u háº¿t non-converter
- **F1-Score**: Cao (khÃ´ng cÃ´ng bá»‘ chÃ­nh xÃ¡c do Ä‘á»‹nh nghÄ©a)
- **Support**: 10,922 samples (85.3% cá»§a test set)

**Káº¿t luáº­n**: Model **cá»±c ká»³ giá»i** nháº­n diá»‡n ngÆ°á»i khÃ´ng mua hÃ ng. Äiá»u nÃ y há»£p lÃ½ vÃ¬:

- ÄÃ¢y lÃ  majority class trong test set
- Model Ä‘Æ°á»£c train vá»›i accuracy metric optimization
- Default threshold 0.5 cao so vá»›i tá»· lá»‡ positive thá»±c táº¿ (14.7%)

#### Class 1 (Purchase/Conversion) - **Lá»šP Yáº¾U** ğŸ˜¢

- **Precision**: 0.57% (khi dá»± Ä‘oÃ¡n lÃ  mua â†’ chá»‰ Ä‘Ãºng 0.57%)
- **Recall**: 0.64% - Chá»‰ báº¯t Ä‘Æ°á»£c 11/1,878 converter thá»±c táº¿
- **F1-Score**: 0.0011 - Cá»±c ká»³ tháº¥p
- **Support**: 1,878 samples (14.7% cá»§a test set)

**Káº¿t luáº­n**: Model **cá»±c ká»³ yáº¿u** vá»›i class 1. NguyÃªn nhÃ¢n:

1. **Class imbalance nghiÃªm trá»ng** (14.7% vs 85.3%)
2. **Threshold khÃ´ng phÃ¹ há»£p** (0.5 quÃ¡ cao)
3. **Model conservative** - khÃ´ng dÃ¡m dá»± Ä‘oÃ¡n positive Ä‘á»ƒ trÃ¡nh False Positive

---

### 4. Bias vá» Majority Class

**PhÃ¢n tÃ­ch prediction distribution**:

```
XGBoost predictions:
- Class 0: 12,782 samples (99.86%)
- Class 1: 18 samples (0.14%)

Actual distribution:
- Class 0: 10,922 samples (85.30%)
- Class 1: 1,878 samples (14.70%)
```

**Káº¿t luáº­n**: Model cÃ³ **SEVERE BIAS vá» majority class**

- Model dá»± Ä‘oÃ¡n class 1 Ã­t hÆ¡n thá»±c táº¿ **100+ láº§n** (0.14% vs 14.7%)
- Model "quÃ¡ sá»£" False Positive nÃªn dá»± Ä‘oÃ¡n conservative
- Äiá»u nÃ y phá»• biáº¿n trong imbalanced dataset khi optimize accuracy

---

### 5. Threshold Optimization

**Optimal Threshold = 0.26** (thay vÃ¬ 0.5 default)

| Threshold | Accuracy   | Precision  | Recall     | F1-Score   | Predicted Positive % |
| --------- | ---------- | ---------- | ---------- | ---------- | -------------------- |
| 0.10      | 56.34%     | 0.1646     | 0.7635     | 0.2697     | 68.52%               |
| 0.20      | 71.77%     | 0.1769     | 0.6636     | 0.2791     | 52.49%               |
| **0.26**  | **77.88%** | **0.1830** | **0.5916** | **0.2795** | **42.82%**           |
| 0.30      | 81.13%     | 0.1895     | 0.5181     | 0.2766     | 36.10%               |
| 0.50      | 85.31%     | 0.0057     | 0.0064     | 0.0011     | 0.14%                |

**PhÃ¢n tÃ­ch**:

- âœ… **F1-Score tÄƒng 254 láº§n** (0.0011 â†’ 0.2795) khi dÃ¹ng threshold 0.26
- âœ… **Recall tÄƒng tá»« 0.64% â†’ 59.16%** - Báº¯t Ä‘Æ°á»£c nhiá»u converter hÆ¡n
- âš ï¸ **Accuracy giáº£m** (85.31% â†’ 77.88%) - Cháº¥p nháº­n Ä‘Æ°á»£c
- âš ï¸ **Precision váº«n tháº¥p** (18.30%) - 81.7% dá»± Ä‘oÃ¡n positive lÃ  sai

**Trade-off**:

- Náº¿u optimize **F1** hoáº·c **Recall**: DÃ¹ng threshold 0.26
- Náº¿u optimize **Accuracy**: DÃ¹ng threshold 0.5 (khÃ´ng khuyáº¿n khÃ­ch vá»›i imbalanced data)
- Náº¿u optimize **Precision**: DÃ¹ng threshold cao hÆ¡n 0.5

**Business recommendation**:

- **Threshold = 0.26** phÃ¹ há»£p náº¿u chi phÃ­ gá»­i promo tháº¥p, muá»‘n Ğ¾Ñ…Ğ²Ğ°Ñ‚ nhiá»u potential converter
- **Threshold = 0.30-0.35** phÃ¹ há»£p náº¿u cáº§n balance giá»¯a precision vÃ  recall

---

## âš ï¸ Váº¤N Äá»€ PHÃT HIá»†N

### 1. Class Imbalance Handling - CHÆ¯A Tá»I Æ¯U

**Váº¥n Ä‘á»**:

- SMOTE chá»‰ balance training data (50-50)
- Test data váº«n imbalanced (14.7% positive)
- Model há»c pattern tá»« balanced data nhÆ°ng evaluate trÃªn imbalanced data
- Mismatch giá»¯a training vÃ  deployment distribution

**Impact**:

- Model khÃ´ng há»c cÃ¡ch handle imbalanced distribution
- Threshold máº·c Ä‘á»‹nh 0.5 khÃ´ng phÃ¹ há»£p vá»›i 14.7% positive rate
- F1-score tháº¥p táº¡i default threshold

**Gá»£i Ã½**:

- âœ… Giá»¯ SMOTE nhÆ°ng **thÃªm class weights** trong model
- âœ… Calibrate threshold trÃªn validation set imbalanced
- âœ… DÃ¹ng **stratified sampling** Ä‘á»ƒ validation set reflect production
- âŒ KhÃ´ng chá»‰ dá»±a vÃ o accuracy Ä‘á»ƒ evaluate

---

### 2. Evaluation Metric - CHá»ŒN SAI

**Váº¥n Ä‘á»**:

- Primary metric: Accuracy - **KHÃ”NG PHÃ™ Há»¢P** vá»›i imbalanced data
- CÃ³ thá»ƒ Ä‘áº¡t 85.3% accuracy chá»‰ báº±ng cÃ¡ch dá»± Ä‘oÃ¡n toÃ n bá»™ class 0
- F1-score lÃ  metric tá»‘t hÆ¡n nhÆ°ng chÆ°a Ä‘Æ°á»£c optimize trong training

**Impact**:

- Model optimize sai hÆ°á»›ng (accuracy instead of F1/ROC-AUC)
- KhÃ´ng reflect business value (báº¯t Ä‘Æ°á»£c converter quan trá»ng hÆ¡n Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ)

**Gá»£i Ã½**:

- âœ… **Primary metric: ROC-AUC** hoáº·c **PR-AUC** (Ä‘Ã£ dÃ¹ng ROC-AUC - tá»‘t!)
- âœ… **Secondary metric: F1-Score táº¡i optimal threshold**
- âœ… Monitor Precision-Recall curve thay vÃ¬ chá»‰ ROC curve
- âŒ KhÃ´ng dÃ¹ng accuracy lÃ m primary metric

---

### 3. Threshold Selection - KHÃ”NG PHÃ™ Há»¢P BUSINESS

**Váº¥n Ä‘á»**:

- Default threshold 0.5 khÃ´ng phÃ¹ há»£p vá»›i:
  - Base rate 14.7%
  - Business cost/benefit asymmetric
- KhÃ´ng cÃ³ analysis vá» business cost cá»§a FP vs FN

**Impact**:

- Model deploy vá»›i threshold 0.5 â†’ háº§u nhÆ° khÃ´ng báº¯t Ä‘Æ°á»£c converter
- LÃ£ng phÃ­ tiá»m nÄƒng cá»§a model (ROC-AUC 0.634 lÃ  tá»‘t!)

**Gá»£i Ã½**:

- âœ… **Threshold = 0.26** cho F1 optimization (Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c!)
- âœ… **Business-informed threshold**:
  - Cost of sending promo to non-converter: $X
  - Benefit of converting a customer: $Y
  - Optimal threshold = X / (X + Y)
- âœ… Monitor threshold performance over time
- âœ… A/B testing different thresholds in production

---

### 4. Model Capacity - CÃ“ Dáº¤U HIá»†U UNDERFITTING NHáº¸

**Train vs Test Performance**:

| Model             | ROC-AUC Train (CV) | ROC-AUC Test | Diff   | Status     |
| ----------------- | ------------------ | ------------ | ------ | ---------- |
| XGBoost           | 0.6344             | 0.6344       | 0.0000 | âœ… Perfect |
| Gradient Boosting | 0.6341             | 0.6341       | 0.0000 | âœ… Perfect |
| Random Forest     | 0.5900             | 0.5900       | 0.0000 | âœ… Perfect |

**PhÃ¢n tÃ­ch**:

- âœ… **KHÃ”NG cÃ³ overfitting** - Train/test performance gáº§n nhÆ° identical
- âš ï¸ **CÃ³ thá»ƒ bá»‹ underfitting** - ROC-AUC 0.634 chÆ°a cao (trung bÃ¬nh)
- â„¹ï¸ Perfect match giá»¯a train/test cÃ³ thá»ƒ do:
  - Model complexity vá»«a pháº£i
  - SMOTE táº¡o synthetic data gáº§n vá»›i test distribution
  - Regularization tá»‘t (max_depth=5, subsample=0.8)

**Recommendation**:

- âœ… Thá»­ **tÄƒng model complexity**: max_depth=7-10, n_estimators=300-500
- âœ… Thá»­ **ensemble methods**: Stacking, Voting Classifier
- âœ… Thá»­ **feature engineering** sÃ¢u hÆ¡n: polynomial features, interactions
- âš ï¸ Monitor overfitting náº¿u increase complexity

---

### 5. Feature Engineering - CÃ“ THá»‚ Cáº¢I THIá»†N

**Top 5 Features**:

1. `is_referral` (9.44%) - CÃ³ pháº£i khÃ¡ch giá»›i thiá»‡u
2. `recency` (7.46%) - NgÃ y tá»« láº§n mua cuá»‘i
3. `offer_No Offer` (7.32%) - Control group (khÃ´ng nháº­n offer)
4. `offer_Discount` (5.71%) - Nháº­n discount offer
5. `drink_category_Creamy Tea & Milk` (5.19%) - Loáº¡i Ä‘á»“ uá»‘ng

**Insights**:

- âœ… Features cÃ³ Ã½ nghÄ©a business logic
- âœ… Referral lÃ  predictor máº¡nh nháº¥t (khÃ¡ch giá»›i thiá»‡u trung thÃ nh hÆ¡n)
- âœ… Recency effect rÃµ rÃ ng (RFM analysis)
- âš ï¸ Feature importance tÆ°Æ¡ng Ä‘á»‘i **phÃ¢n tÃ¡n** (top 1 chá»‰ 9.44%)

**Gá»£i Ã½ cáº£i thiá»‡n**:

1. **Interaction features**:

   - `is_referral Ã— offer_type` - KhÃ¡ch giá»›i thiá»‡u respond khÃ¡c nhau vá»›i offer
   - `recency Ã— history` - RFM composite score
   - `drink_category Ã— time_of_day` - Pattern uá»‘ng theo giá»

2. **Temporal features**:

   - `days_since_last_promo` - Thá»i gian tá»« promo cuá»‘i
   - `promo_frequency` - Táº§n suáº¥t nháº­n promo (cÃ³ thá»ƒ promo fatigue)
   - `seasonality` - Theo mÃ¹a/thÃ¡ng

3. **Behavioral features**:

   - `avg_order_value` tá»« history
   - `favorite_category` - Category mua nhiá»u nháº¥t
   - `channel_preference` - Web/Phone preference

4. **Domain-specific features**:
   - `customer_lifetime_value` (CLV)
   - `churn_risk_score`
   - `discount_sensitivity` - Tá»« past behavior

---

## ğŸ” GIáº¢I THÃCH NGUYÃŠN NHÃ‚N

### Táº¡i Sao F1-Score Tháº¥p Máº·c DÃ¹ Accuracy Cao?

**NguyÃªn nhÃ¢n chÃ­nh**: **Paradox cá»§a Imbalanced Classification**

1. **Class imbalance nghiÃªm trá»ng** (85.3% vs 14.7%):

   ```
   Accuracy = (TP + TN) / Total

   Náº¿u dá»± Ä‘oÃ¡n Táº¤T Cáº¢ lÃ  class 0:
   â†’ Accuracy = TN / Total = 10,922 / 12,800 = 85.3%

   Model Ä‘áº¡t 85.31% accuracy â‰ˆ baseline â†’ Model háº§u nhÆ° dá»± Ä‘oÃ¡n toÃ n class 0
   ```

2. **F1-Score pháº¡t máº¥t cÃ¢n báº±ng**:

   ```
   F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)

   Vá»›i Precision = 0.57%, Recall = 0.64%:
   â†’ F1 = 2 Ã— (0.0057 Ã— 0.0064) / (0.0057 + 0.0064) = 0.0011

   F1 cá»±c ká»³ nháº¡y cáº£m vá»›i class minority performance
   ```

3. **Accuracy che giáº¥u thá»±c táº¿**:
   - Accuracy cao khÃ´ng cÃ³ nghÄ©a model tá»‘t
   - F1-Score lá»™ ra sá»± tháº­t: model khÃ´ng báº¯t Ä‘Æ°á»£c class 1

**BÃ i há»c**:

- â›” **KHÃ”NG BAO GIá»œ dÃ¹ng accuracy cho imbalanced data**
- âœ… LuÃ´n check confusion matrix, precision, recall
- âœ… DÃ¹ng ROC-AUC, PR-AUC, F1-Score

---

### Táº¡i Sao Model Dá»± ÄoÃ¡n Conservative (Ãt Positive)?

**NguyÃªn nhÃ¢n**:

1. **Loss function khÃ´ng balance**:

   - Binary cross-entropy loss chuáº©n: `-(y*log(p) + (1-y)*log(1-p))`
   - Vá»›i 85% class 0 â†’ Loss bá»‹ dominated by class 0 errors
   - Model há»c cÃ¡ch minimize error trÃªn class 0, hy sinh class 1

2. **Threshold khÃ´ng calibrated**:

   - Threshold 0.5 giáº£ Ä‘á»‹nh P(class 1) = 50%
   - Thá»±c táº¿ P(class 1) = 14.7%
   - Threshold há»£p lÃ½ hÆ¡n nÃªn â‰ˆ 0.15-0.25

3. **SMOTE side-effect**:
   - SMOTE táº¡o synthetic samples gáº§n vá»›i minority class
   - CÃ³ thá»ƒ lÃ m minority class "dá»… há»c hÆ¡n" trong training
   - NhÆ°ng test data váº«n cÃ³ noise â†’ Model cáº©n tháº­n hÆ¡n

**Giáº£i phÃ¡p**:

1. **Class weights trong loss function**:

   ```python
   class_weight = {0: 1.0, 1: 5.8}  # 85.3/14.7 â‰ˆ 5.8
   # hoáº·c
   class_weight = 'balanced'  # auto calculate
   ```

2. **Threshold calibration**:

   ```python
   optimal_threshold = y_train.mean()  # â‰ˆ 0.147
   # hoáº·c optimize trÃªn validation set
   ```

3. **Cost-sensitive learning**:
   ```python
   # Assign higher cost to FN (miss a converter)
   cost_matrix = [[0, 1],    # TN, FP
                  [10, 0]]   # FN, TP
   ```

---

### Vai TrÃ² cá»§a SMOTE

**SMOTE Ä‘Ã£ lÃ m gÃ¬**:

1. âœ… Balance training data tá»« imbalanced â†’ 50-50
2. âœ… Táº¡o synthetic minority samples Ä‘á»ƒ model há»c Ä‘Æ°á»£c pattern
3. âœ… Cáº£i thiá»‡n recall trÃªn training data

**Háº¡n cháº¿ cá»§a SMOTE**:

1. âš ï¸ Táº¡o synthetic data cÃ³ thá»ƒ khÃ´ng realistic
2. âš ï¸ CÃ³ thá»ƒ táº¡o noise náº¿u minority class overlap vá»›i majority
3. âš ï¸ KhÃ´ng giáº£i quyáº¿t root cause: distribution mismatch train/test

**Táº¡i sao váº«n F1 tháº¥p?**:

- SMOTE chá»‰ balance **training data**
- **Test data** váº«n imbalanced (14.7%)
- Model há»c tá»« 50-50 nhÆ°ng deploy trÃªn 14.7%
- Cáº§n **threshold adjustment** Ä‘á»ƒ bridge gap nÃ y

**Alternative approaches**:

1. **No SMOTE + Class weights**:

   ```python
   xgb.XGBClassifier(scale_pos_weight=5.8)  # 85.3/14.7
   ```

2. **SMOTE + Class weights** (hybrid):

   ```python
   # SMOTE to 30-70 instead of 50-50
   # Then use class_weight=[0.3, 0.7]
   ```

3. **Cost-sensitive SMOTE**:
   ```python
   from imblearn.over_sampling import SMOTE
   smote = SMOTE(sampling_strategy=0.5, k_neighbors=5)
   ```

**Recommendation**:

- Thá»­ **remove SMOTE** vÃ  dÃ¹ng `scale_pos_weight` trong XGBoost
- So sÃ¡nh performance
- SMOTE khÃ´ng pháº£i always better choice

---

### Feature Importance Insights

**Táº¡i sao `is_referral` quan trá»ng nháº¥t?**

1. **Business logic**:

   - KhÃ¡ch giá»›i thiá»‡u thÆ°á»ng trung thÃ nh hÆ¡n
   - CÃ³ Ä‘á»™ng lá»±c máº¡nh (referrer reward)
   - Trust factor cao hÆ¡n (Ä‘Æ°á»£c báº¡n bÃ¨ giá»›i thiá»‡u)

2. **Statistical pattern**:
   - Referral customers cÃ³ conversion rate cao hÆ¡n Ä‘Ã¡ng ká»ƒ
   - Model há»c Ä‘Æ°á»£c clear signal tá»« feature nÃ y
   - Low noise, high predictive power

**Táº¡i sao `recency` quan trá»ng?**

1. **RFM principle**:

   - Recency, Frequency, Monetary - golden rules of marketing
   - KhÃ¡ch mua gáº§n Ä‘Ã¢y â†’ likely to buy again
   - Recency cao â†’ may have churned

2. **Time decay effect**:
   - Engagement giáº£m theo thá»i gian
   - Promo cÃ³ hiá»‡u quáº£ hÆ¡n vá»›i recent customers

**Táº¡i sao `offer_No Offer` quan trá»ng?**

1. **Control group analysis**:

   - Customers khÃ´ng nháº­n offer = organic converters
   - Model há»c Ä‘Æ°á»£c baseline conversion behavior
   - Contrast vá»›i BOGO/Discount effect

2. **Selection bias**:
   - Control group cÃ³ thá»ƒ cÃ³ characteristics khÃ¡c biá»‡t
   - Model detect vÃ  sá»­ dá»¥ng signal nÃ y

**Action items**:

- âœ… **Prioritize referral program** - ROI cao nháº¥t
- âœ… **Retarget recent customers** vá»›i personalized offers
- âœ… **A/B test offer types** Ä‘á»ƒ optimize conversion
- âœ… Create features combining top 3 factors

---

## ğŸ› ï¸ Gá»¢I Ã Cáº¢I THIá»†N

### 1. Xá»­ LÃ½ Imbalance - NGAY Láº¬P Tá»¨C

#### Option A: Class Weights (Recommended â­)

```python
# XGBoost
xgb_model = xgb.XGBClassifier(
    scale_pos_weight=5.8,  # 85.3 / 14.7
    learning_rate=0.1,
    max_depth=5,
    n_estimators=200,
    subsample=0.8,
    colsample_bytree=0.8
)

# Gradient Boosting / Random Forest
from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight('balanced',
                                     classes=np.unique(y_train),
                                     y=y_train)
```

**Pros**:

- âœ… KhÃ´ng táº¡o synthetic data
- âœ… Faster training (no SMOTE overhead)
- âœ… No risk of overfitting to synthetic samples

**Cons**:

- âš ï¸ CÃ³ thá»ƒ tÄƒng False Positives
- âš ï¸ Cáº§n tune weight carefully

#### Option B: SMOTE + Threshold Calibration (Current + Improvement)

```python
# Giá»¯ SMOTE nhÆ°ng set optimal threshold
threshold = 0.26  # From optimization analysis

# Hoáº·c use custom threshold per business need
```

**Pros**:

- âœ… ÄÃ£ cÃ³ baseline (current approach)
- âœ… F1 Ä‘Ã£ improve tá»« 0.001 â†’ 0.28

**Cons**:

- âš ï¸ Váº«n cÃ³ SMOTE overhead
- âš ï¸ F1 = 0.28 váº«n chÆ°a thá»±c sá»± cao

#### Option C: Hybrid Approach (Best Practice ğŸ†)

```python
# 1. SMOTE with conservative ratio
smote = SMOTE(sampling_strategy=0.3)  # 30-70 instead of 50-50
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# 2. Train with class weights
xgb_model = xgb.XGBClassifier(
    scale_pos_weight=2.0,  # Äiá»u chá»‰nh nháº¹
    ...
)

# 3. Calibrate threshold
optimal_threshold = 0.26
```

**Pros**:

- âœ… Best of both worlds
- âœ… More robust
- âœ… Better generalization

---

### 2. Feature Engineering - TRUNG Háº N

#### Interaction Features

```python
# 1. Referral Ã— Offer interaction
df['referral_offer_bogo'] = df['is_referral'] * df['offer_BOGO']
df['referral_offer_discount'] = df['is_referral'] * df['offer_Discount']

# 2. RFM composite
df['rfm_score'] = (
    df['recency'].rank(pct=True) * 0.4 +
    df['history'].rank(pct=True) * 0.6
)

# 3. Category Ã— Time interaction
df['creamy_morning'] = df['drink_category_Creamy Tea & Milk'] * df['time_of_day_Morning']
```

#### Behavioral Features

```python
# 4. Discount sensitivity
df['discount_user'] = (df['used_discount'] > 0).astype(int)
df['bogo_user'] = (df['used_bogo'] > 0).astype(int)
df['promo_responsive'] = df['discount_user'] + df['bogo_user']

# 5. Purchase patterns
df['avg_days_between_purchase'] = df['recency'] / df['history'].clip(lower=1)
df['high_value_customer'] = (df['history'] > df['history'].quantile(0.75)).astype(int)
```

#### Temporal Features

```python
# 6. Seasonality (if date available)
df['month'] = df['date'].dt.month
df['is_holiday_season'] = df['month'].isin([11, 12, 1]).astype(int)
df['is_weekend'] = df['date'].dt.dayofweek.isin([5, 6]).astype(int)
```

**Expected Impact**: +5-10% ROC-AUC improvement

---

### 3. Hyperparameter Tuning - TRUNG Háº N

#### XGBoost Fine-tuning

```python
# Current best params (baseline)
current_params = {
    'learning_rate': 0.1,
    'max_depth': 5,
    'n_estimators': 200,
    'colsample_bytree': 0.8,
    'subsample': 0.8
}

# Suggested tuning space
param_grid = {
    'learning_rate': [0.01, 0.05, 0.1],  # Lower for more trees
    'max_depth': [5, 7, 10],  # Increase complexity
    'n_estimators': [200, 300, 500],  # More trees
    'colsample_bytree': [0.7, 0.8, 0.9],
    'subsample': [0.7, 0.8, 0.9],
    'min_child_weight': [1, 3, 5],  # Add regularization
    'gamma': [0, 0.1, 0.2],  # Add regularization
    'scale_pos_weight': [5.0, 5.8, 7.0]  # Tune class weight
}

# Use RandomizedSearchCV for efficiency
from sklearn.model_selection import RandomizedSearchCV
random_search = RandomizedSearchCV(
    xgb.XGBClassifier(),
    param_distributions=param_grid,
    n_iter=50,  # Try 50 combinations
    cv=5,
    scoring='roc_auc',  # Keep ROC-AUC as primary
    n_jobs=-1,
    random_state=42
)
```

**Priority params to tune**:

1. ğŸ”¥ `scale_pos_weight` - Biggest impact on imbalance
2. ğŸ”¥ `max_depth`, `n_estimators` - Model capacity
3. âš¡ `learning_rate` - Fine-tune vá»›i n_estimators
4. âš¡ `min_child_weight`, `gamma` - Prevent overfitting

**Expected Impact**: +2-5% ROC-AUC improvement

---

### 4. Ensemble Methods - DÃ€I Háº N

#### Option A: Voting Classifier

```python
from sklearn.ensemble import VotingClassifier

# Soft voting (average probabilities)
ensemble = VotingClassifier(
    estimators=[
        ('xgb', xgb_model),
        ('gb', gb_model),
        ('rf', rf_model)
    ],
    voting='soft',
    weights=[2, 2, 1]  # XGBoost & GB cÃ³ weight cao hÆ¡n
)

ensemble.fit(X_train, y_train)
y_pred_proba = ensemble.predict_proba(X_test)[:, 1]
```

**Expected Impact**: +1-3% ROC-AUC (ensemble usually better)

#### Option B: Stacking

```python
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# Level 0: Base models
base_models = [
    ('xgb', xgb_model),
    ('gb', gb_model),
    ('rf', rf_model)
]

# Level 1: Meta-learner
stacking = StackingClassifier(
    estimators=base_models,
    final_estimator=LogisticRegression(),
    cv=5
)

stacking.fit(X_train, y_train)
```

**Expected Impact**: +2-4% ROC-AUC (usually best ensemble method)

#### Option C: Blending

```python
# Train on 80% of training data
X_train_blend, X_val_blend, y_train_blend, y_val_blend = train_test_split(
    X_train, y_train, test_size=0.2, stratify=y_train
)

# Get predictions from base models on validation set
xgb_pred = xgb_model.predict_proba(X_val_blend)[:, 1]
gb_pred = gb_model.predict_proba(X_val_blend)[:, 1]
rf_pred = rf_model.predict_proba(X_val_blend)[:, 1]

# Train meta-learner
meta_features = np.column_stack([xgb_pred, gb_pred, rf_pred])
meta_model = LogisticRegression()
meta_model.fit(meta_features, y_val_blend)
```

---

### 5. Alternative Models - DÃ€I Háº N

#### Deep Learning (Neural Network)

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization

model = Sequential([
    Dense(128, activation='relu', input_shape=(23,)),
    BatchNormalization(),
    Dropout(0.3),

    Dense(64, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),

    Dense(32, activation='relu'),
    BatchNormalization(),
    Dropout(0.2),

    Dense(1, activation='sigmoid')
])

# Class weights for imbalance
class_weight = {0: 1.0, 1: 5.8}

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['AUC']
)

model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=50,
    batch_size=128,
    class_weight=class_weight,
    callbacks=[EarlyStopping(patience=10)]
)
```

**Pros**:

- âœ… CÃ³ thá»ƒ há»c non-linear patterns phá»©c táº¡p
- âœ… Flexible architecture
- âœ… Good for large datasets

**Cons**:

- âš ï¸ Cáº§n nhiá»u data hÆ¡n (87K cÃ³ thá»ƒ á»•n)
- âš ï¸ Harder to interpret
- âš ï¸ Longer training time

**Expected Impact**: +0-5% ROC-AUC (depends on data complexity)

#### LightGBM (Alternative to XGBoost)

```python
import lightgbm as lgb

lgb_model = lgb.LGBMClassifier(
    learning_rate=0.1,
    max_depth=5,
    n_estimators=200,
    num_leaves=31,
    scale_pos_weight=5.8,
    subsample=0.8,
    colsample_bytree=0.8
)
```

**Pros**:

- âœ… Faster than XGBoost
- âœ… Better with categorical features
- âœ… Lower memory usage

**Expected Impact**: Similar to XGBoost, worth trying

#### CatBoost (Handles categorical features natively)

```python
from catboost import CatBoostClassifier

cat_model = CatBoostClassifier(
    iterations=200,
    learning_rate=0.1,
    depth=5,
    scale_pos_weight=5.8,
    cat_features=['zip_code', 'channel', 'offer', ...]  # Auto-handle
)
```

**Pros**:

- âœ… Excellent with categorical features
- âœ… No need for manual encoding
- âœ… Often best performance out-of-the-box

**Expected Impact**: +1-3% ROC-AUC

---

### 6. Business-Informed Threshold - NGAY Láº¬P Tá»¨C

#### Cost-Benefit Analysis

```python
# Define business costs
COST_PROMO = 2.0  # $2 per promotional offer sent
BENEFIT_CONVERSION = 15.0  # $15 profit per conversion
COST_FP = COST_PROMO  # False Positive = wasted promo
COST_FN = BENEFIT_CONVERSION  # False Negative = missed profit

# Calculate optimal threshold
def business_profit(y_true, y_pred, threshold):
    y_pred_binary = (y_pred >= threshold).astype(int)
    cm = confusion_matrix(y_true, y_pred_binary)
    tn, fp, fn, tp = cm.ravel()

    profit = (
        tp * (BENEFIT_CONVERSION - COST_PROMO) +  # True Positive profit
        tn * 0 +  # True Negative (no action)
        fp * (-COST_FP) +  # False Positive cost
        fn * 0  # False Negative (no action, no cost but missed opportunity)
    )

    return profit

# Find optimal threshold
thresholds = np.arange(0.05, 0.95, 0.01)
profits = [business_profit(y_test, probabilities['XGBoost'], t) for t in thresholds]
optimal_idx = np.argmax(profits)
optimal_threshold_business = thresholds[optimal_idx]

print(f"Optimal threshold (business): {optimal_threshold_business:.2f}")
print(f"Expected profit: ${profits[optimal_idx]:,.2f}")
```

**Expected Output**:

- Optimal threshold: ~0.20-0.30 (depends on costs)
- This maximizes business value, not F1-score

---

## ğŸ¯ KHUYáº¾N NGHá»Š CUá»I CÃ™NG

### Priority 1: IMMEDIATE ACTIONS (1-2 ngÃ y)

1. **âœ… Deploy vá»›i Threshold = 0.26**

   - Ngay láº­p tá»©c cáº£i thiá»‡n F1 tá»« 0.001 â†’ 0.28 (254x)
   - Recall tá»« 0.64% â†’ 59.16% (92x)
   - Chi phÃ­: $0, effort: 5 phÃºt
   - **ROI**: â­â­â­â­â­

2. **âœ… Implement Class Weights**

   - Train láº¡i XGBoost vá»›i `scale_pos_weight=5.8`
   - Compare vá»›i current model
   - Chi phÃ­: 1 giá» training time
   - **ROI**: â­â­â­â­â­

3. **âœ… Business Threshold Optimization**
   - Calculate optimal threshold dá»±a trÃªn promo cost vs conversion benefit
   - Deploy threshold phÃ¹ há»£p business
   - Chi phÃ­: 2 giá» analysis
   - **ROI**: â­â­â­â­â­

---

### Priority 2: SHORT-TERM (1-2 tuáº§n)

4. **âš¡ Feature Engineering - Phase 1**

   - Implement top 5 interaction features (referralÃ—offer, RFM, categoryÃ—time)
   - Retrain vÃ  evaluate
   - Expected improvement: +5-7% ROC-AUC
   - **ROI**: â­â­â­â­

5. **âš¡ Hyperparameter Tuning**

   - RandomizedSearchCV vá»›i expanded param grid
   - Focus on scale_pos_weight, max_depth, n_estimators
   - Expected improvement: +2-5% ROC-AUC
   - **ROI**: â­â­â­â­

6. **âš¡ Try Alternative Models**
   - LightGBM, CatBoost
   - Compare vá»›i XGBoost
   - Expected improvement: +1-3% ROC-AUC
   - **ROI**: â­â­â­

---

### Priority 3: MEDIUM-TERM (1 thÃ¡ng)

7. **ğŸ”„ Ensemble Methods**

   - Stacking: XGBoost + GB + RF
   - Expected improvement: +2-4% ROC-AUC
   - **ROI**: â­â­â­â­

8. **ğŸ”„ Feature Engineering - Phase 2**

   - Behavioral features, temporal features
   - Domain-specific features (CLV, churn risk)
   - Expected improvement: +3-5% ROC-AUC
   - **ROI**: â­â­â­

9. **ğŸ”„ SHAP Analysis**
   - Model interpretability
   - Feature interaction insights
   - Guide next iteration of feature engineering
   - **ROI**: â­â­â­ (indirect value)

---

### Priority 4: LONG-TERM (2-3 thÃ¡ng)

10. **ğŸš€ Deep Learning**

    - Neural Network vá»›i custom architecture
    - Experiment vá»›i different architectures
    - Expected improvement: +0-5% ROC-AUC
    - **ROI**: â­â­ (high effort, uncertain gain)

11. **ğŸš€ A/B Testing Framework**

    - Deploy multiple thresholds
    - Measure real-world performance
    - Continuous optimization
    - **ROI**: â­â­â­â­â­ (long-term)

12. **ğŸš€ Production Monitoring**
    - Model drift detection
    - Performance monitoring
    - Auto-retraining pipeline
    - **ROI**: â­â­â­â­â­ (long-term)

---

### Expected Performance Roadmap

| Milestone                             | ROC-AUC  | F1-Score   | Recall     | Timeline   |
| ------------------------------------- | -------- | ---------- | ---------- | ---------- |
| **Current (threshold=0.5)**           | 0.6344   | 0.0011     | 0.64%      | Now        |
| **Phase 1: Threshold fix**            | 0.6344   | **0.2795** | **59.16%** | Week 1     |
| **Phase 2: Class weights + tuning**   | **0.68** | **0.32**   | **65%**    | Week 2-3   |
| **Phase 3: Feature engineering**      | **0.72** | **0.38**   | **70%**    | Week 4-6   |
| **Phase 4: Ensemble**                 | **0.75** | **0.42**   | **75%**    | Week 7-10  |
| **Phase 5: Deep Learning (optional)** | **0.77** | **0.45**   | **78%**    | Week 11-16 |

---

### Decision Framework

**Náº¿u cáº§n káº¿t quáº£ NGAY (1-2 ngÃ y)**:
â†’ Priority 1 actions (threshold + class weights)
â†’ Expected: F1 = 0.28-0.32, Recall = 60-65%

**Náº¿u cÃ³ 2-3 tuáº§n**:
â†’ Priority 1 + 2 (feature engineering + tuning)
â†’ Expected: F1 = 0.35-0.40, Recall = 65-72%

**Náº¿u muá»‘n best possible model (2-3 thÃ¡ng)**:
â†’ All priorities
â†’ Expected: F1 = 0.42-0.48, Recall = 75-80%

---

## ğŸ“‹ CHECKLIST HÃ€NH Äá»˜NG

### Immediate (Week 1)

- [ ] Deploy XGBoost vá»›i threshold = 0.26
- [ ] Train XGBoost vá»›i scale_pos_weight = 5.8
- [ ] Calculate business-informed threshold
- [ ] Compare 3 approaches: threshold 0.26 vs class weight vs business threshold
- [ ] Document results vÃ  choose best approach

### Short-term (Week 2-4)

- [ ] Implement 5 interaction features
- [ ] Run RandomizedSearchCV vá»›i expanded params
- [ ] Train LightGBM vÃ  CatBoost
- [ ] Compare all models
- [ ] Update production model

### Medium-term (Week 5-10)

- [ ] Build stacking ensemble
- [ ] Implement 10 additional features (behavioral + temporal)
- [ ] SHAP analysis cho feature insights
- [ ] Validate performance trÃªn hold-out set

### Long-term (Week 11+)

- [ ] Experiment vá»›i Deep Learning
- [ ] Setup A/B testing framework
- [ ] Build monitoring dashboard
- [ ] Implement auto-retraining pipeline

---

## ğŸ“ BÃ€I Há»ŒC RÃšT RA

### 1. Imbalanced Classification is Hard

- Accuracy lÃ  misleading metric
- Always check confusion matrix
- Threshold optimization is critical
- SMOTE alone is not enough

### 2. Model Performance â‰  Business Value

- High accuracy â‰  good model cho business
- Cáº§n translate metrics to business outcomes
- Threshold pháº£i reflect business costs
- Deploy model cáº§n business context

### 3. Feature Engineering > Algorithm Selection

- 23 features cÃ³ thá»ƒ chÆ°a Ä‘á»§
- Interaction features often powerful
- Domain knowledge is key
- Feature importance guides next steps

### 4. Evaluation Must Be Comprehensive

- Multiple metrics (ROC-AUC, F1, Precision, Recall)
- Train/test comparison (overfitting check)
- Per-class analysis
- Sample predictions vÃ  error analysis
- Business profit calculation

### 5. Iterative Improvement is Key

- Start vá»›i quick wins (threshold)
- Build progressively (class weights â†’ features â†’ ensemble)
- Measure impact at each step
- Don't jump to complex solutions (DL) without exhausting simple ones

---

## ğŸ† Káº¾T LUáº¬N

### Model Hiá»‡n Táº¡i: **FAIR** (6/10)

**Äiá»ƒm máº¡nh**:

- âœ… ROC-AUC 0.634 - Decent discriminative power
- âœ… No overfitting - Good generalization
- âœ… Feature engineering cÃ³ Ã½ nghÄ©a business
- âœ… Proper train/test split vÃ  validation

**Äiá»ƒm yáº¿u**:

- âŒ F1-Score cá»±c tháº¥p (0.001) táº¡i default threshold
- âŒ Chá»‰ báº¯t Ä‘Æ°á»£c 0.64% converter (Recall)
- âŒ Class imbalance chÆ°a handle tá»‘t
- âŒ Threshold khÃ´ng phÃ¹ há»£p business

**Overall Assessment**:
Model cÃ³ **tiá»m nÄƒng tá»‘t** (ROC-AUC 0.634) nhÆ°ng **deploy khÃ´ng hiá»‡u quáº£** (F1 = 0.001). Cáº§n threshold optimization vÃ  class weight tuning Ä‘á»ƒ unlock tiá»m nÄƒng.

### Khuyáº¿n Nghá»‹ Deploy:

**ğŸ¯ Recommended Setup**:

```python
model = XGBoost vá»›i scale_pos_weight=5.8
threshold = 0.26 (hoáº·c business-optimized threshold)
expected_f1 = 0.28-0.32
expected_recall = 59-65%
```

**Business Impact Projection**:

- Vá»›i threshold 0.26: Báº¯t Ä‘Æ°á»£c **59% converters** (vs 0.64% current)
- Precision 18%: **82% promo Ä‘áº¿n non-converter** (acceptable náº¿u promo cost tháº¥p)
- Trade-off: TÄƒng 92x Recall, cháº¥p nháº­n lower precision

**Ready for Production?**:

- âœ… **YES** vá»›i threshold optimization
- âš ï¸ Recommend A/B test vá»›i control group
- ğŸ”„ Plan cho iteration 2 (feature engineering + class weights)

---

**TÃ i liá»‡u nÃ y Ä‘Æ°á»£c táº¡o bá»Ÿi**: ML Expert Evaluation System  
**NgÃ y**: 18/11/2025  
**Version**: 1.0  
**Next Review**: After Priority 1 actions completed
